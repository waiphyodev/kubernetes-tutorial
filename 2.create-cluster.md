# Create Cluster

## Create a cluster with `kind`

### 1. Create a `cluster.yaml` file

```
kind: Cluster
apiVersion: kind.x-k8s.io/v1alpha4
nodes:
- role: control-plane
  image: kindest/node:v1.29.4@sha256:3abb816a5b1061fb15c6e9e60856ec40d56b7b52bcea5f5f1350bc6e2320b6f8
- role: worker
  image: kindest/node:v1.29.4@sha256:3abb816a5b1061fb15c6e9e60856ec40d56b7b52bcea5f5f1350bc6e2320b6f8
- role: worker
  image: kindest/node:v1.29.4@sha256:3abb816a5b1061fb15c6e9e60856ec40d56b7b52bcea5f5f1350bc6e2320b6f8
networking:
  disableDefaultCNI: false
  # podSubnet: 192.168.0.0/16
```

### 2. Create cluster as root using `kind create cluster`

```
kind create cluster --config cluster.yaml -n agb
```

```
enabling experimental podman provider
Creating cluster "agb" ...
 ✓ Ensuring node image (kindest/node:v1.29.4) 🖼 
 ✓ Preparing nodes 📦 📦 📦  
 ✓ Writing configuration 📜 
 ✓ Starting control-plane 🕹️ 
 ✓ Installing CNI 🔌 
 ✓ Installing StorageClass 💾 
 ✓ Joining worker nodes 🚜 
Set kubectl context to "kind-agb"
You can now use your cluster with:

kubectl cluster-info --context kind-agb

Not sure what to do next? 😅  Check out https://kind.sigs.k8s.io/docs/user/quick-start/
```

### 3. Check the cluster info as root as `kind` mentioned

```
sudo kubectl cluster-info --context kind-agb
```

```
Kubernetes control plane is running at https://127.0.0.1:45525
CoreDNS is running at https://127.0.0.1:45525/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy

To further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.
```

```
sudo kubectl get nodes -o wide
```

```
NAME                STATUS   ROLES           AGE   VERSION   INTERNAL-IP   EXTERNAL-IP   OS-IMAGE                         KERNEL-VERSION     CONTAINER-RUNTIME
agb-control-plane   Ready    control-plane   10h   v1.29.4   10.89.0.4     <none>        Debian GNU/Linux 12 (bookworm)   6.8.0-39-generic   containerd://1.7.15
agb-worker          Ready    <none>          10h   v1.29.4   10.89.0.3     <none>        Debian GNU/Linux 12 (bookworm)   6.8.0-39-generic   containerd://1.7.15
agb-worker2         Ready    <none>          10h   v1.29.4   10.89.0.2     <none>        Debian GNU/Linux 12 (bookworm)   6.8.0-39-generic   containerd://1.7.15

```

As we declare in `yaml` file, the cluster is running with 2 worker nodes.

```
sudo kubectl get pods
```

### 4. Print out the cluster config as root with `kind get kubeconfig`
